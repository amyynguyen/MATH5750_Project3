{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Math 5750/6880: Mathematics of Data Science \\\n",
        "Project 3"
      ],
      "metadata": {
        "id": "0gdC70xxFyc4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Fashion-MNIST image classification using sklearn"
      ],
      "metadata": {
        "id": "i9_7SnpMGKDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(len(X_train), -1)\n",
        "X_test  = X_test.reshape(len(X_test), -1)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AB136H0PGKq1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# your code here\n",
        "import time\n",
        "\n",
        "# Define a baseline MLP model\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu',\n",
        "                    solver='adam', max_iter=20, random_state=42)\n",
        "\n",
        "start = time.time()\n",
        "mlp.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "\n",
        "# Predictions\n",
        "y_pred = mlp.predict(X_test)\n",
        "\n",
        "# Evaluation\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Training time: {end - start:.2f} seconds\")\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "mlp2 = MLPClassifier(hidden_layer_sizes=(256, 128),\n",
        "                     activation='relu',\n",
        "                     solver='adam',\n",
        "                     learning_rate_init=0.0005,\n",
        "                     early_stopping=True,\n",
        "                     max_iter=30,\n",
        "                     random_state=42)\n",
        "\n",
        "start = time.time()\n",
        "mlp2.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "\n",
        "y_pred2 = mlp2.predict(X_test)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred2):.4f}\")\n",
        "print(f\"Training time: {end - start:.2f} seconds\")"
      ],
      "metadata": {
        "id": "5GAsN-dmHjRM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95aabfc2-a824-48e6-99a3-b236bf54b1f3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8804\n",
            "Training time: 50.94 seconds\n",
            "Confusion Matrix:\n",
            " [[768   3  17  28   7   0 168   0   9   0]\n",
            " [  2 973   1  16   4   0   3   0   1   0]\n",
            " [ 13   1 781  14 116   1  74   0   0   0]\n",
            " [ 17  10  12 884  38   0  36   0   3   0]\n",
            " [  1   1  61  23 862   1  49   0   2   0]\n",
            " [  0   0   0   1   0 955   0  27   1  16]\n",
            " [ 79   2  80  27  74   0 729   0   9   0]\n",
            " [  0   0   0   0   0  16   0 972   0  12]\n",
            " [  9   0   6   3   7   5   8   4 957   1]\n",
            " [  0   0   1   0   0  10   1  63   2 923]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.77      0.81      1000\n",
            "           1       0.98      0.97      0.98      1000\n",
            "           2       0.81      0.78      0.80      1000\n",
            "           3       0.89      0.88      0.89      1000\n",
            "           4       0.78      0.86      0.82      1000\n",
            "           5       0.97      0.95      0.96      1000\n",
            "           6       0.68      0.73      0.71      1000\n",
            "           7       0.91      0.97      0.94      1000\n",
            "           8       0.97      0.96      0.96      1000\n",
            "           9       0.97      0.92      0.95      1000\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Accuracy: 0.8873\n",
            "Training time: 150.22 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Fashion-MNIST image classification  using pytorch"
      ],
      "metadata": {
        "id": "a2qcKggmIH8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Load Fashion-MNIST\n",
        "# Classes (0-9): T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal, Shirt, Sneaker, Bag, Ankle boot\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# scale to [0,1], add channel dimension -> (N, 1, 28, 28)\n",
        "X_train = (X_train.astype(\"float32\") / 255.0)[:, None, :, :]\n",
        "X_test  = (X_test.astype(\"float32\")  / 255.0)[:,  None, :, :]\n",
        "\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test  = y_test.astype(np.int64)\n",
        "\n",
        "# train/val split: last 10k of train as validation\n",
        "X_tr, X_val = X_train[:50000], X_train[50000:]\n",
        "y_tr, y_val = y_train[:50000], y_train[50000:]\n",
        "\n",
        "# wrap in PyTorch TensorDatasets and DataLoaders\n",
        "train_ds = TensorDataset(torch.from_numpy(X_tr),  torch.from_numpy(y_tr))\n",
        "val_ds   = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(y_val))\n",
        "test_ds  = TensorDataset(torch.from_numpy(X_test), torch.from_numpy(y_test))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=128, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=256, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=256, shuffle=False)"
      ],
      "metadata": {
        "id": "B9IQwhgcIVOl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# In colab, you should ``change runtime type'' to GPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# your code here\n",
        "# ----- 1. Define a simple CNN model -----\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv2d(1, 16, 3, padding=1)  # 1 input channel â†’ 16 filters\n",
        "        self.pool = nn.MaxPool2d(2, 2)              # reduce image size by half\n",
        "        self.fc = nn.Linear(16 * 14 * 14, 10)       # fully connected layer (10 classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(-1, 16 * 14 * 14)  # flatten\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# ----- 2. Create model, loss function, and optimizer -----\n",
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# ----- 3. Train the model -----\n",
        "for epoch in range(5):  # small number of epochs for simplicity\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch)\n",
        "        loss = criterion(outputs, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# ----- 4. Evaluate on test set -----\n",
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for X_test, y_test in test_loader:\n",
        "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
        "        outputs = model(X_test)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += y_test.size(0)\n",
        "        correct += (predicted == y_test).sum().item()\n",
        "\n",
        "print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "id": "0REsDBunNmEl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61209afa-1a02-4a42-8741-c0a3fc7dd9d7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Epoch 1, Loss: 0.6025\n",
            "Epoch 2, Loss: 0.3716\n",
            "Epoch 3, Loss: 0.3308\n",
            "Epoch 4, Loss: 0.3098\n",
            "Epoch 5, Loss: 0.2923\n",
            "Test Accuracy: 88.25%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s1I-3OXKDxU9"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}